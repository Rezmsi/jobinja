{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ae43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from kafka import KafkaProducer , KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf31383",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_Step1_NAME=\"raw_datas\"\n",
    "TOPIC_Step2_NAME=\"jobs_info\"\n",
    "KAFKA_SERVER=\"broker:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00274c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=KAFKA_SERVER,  value_serializer=lambda m: json.dumps(m).encode('utf-8') )\n",
    "delay = 3   \n",
    "x=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979a6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "     TOPIC_Step1_NAME,\n",
    "     bootstrap_servers=[KAFKA_SERVER],\n",
    "     auto_offset_reset='earliest',\n",
    "     enable_auto_commit=True,\n",
    "     group_id='raw_data',\n",
    "     value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "     key_deserializer=lambda x : str(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f122aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_item(item_url,passed_day):\n",
    "    \n",
    "    res = requests.get(item_url)\n",
    "    time.sleep(delay)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "    \n",
    "    company_name = soup.find('h2' , {'class':'c-companyHeader__name'}).text\n",
    "\n",
    "    title= soup.find('h1').text\n",
    "    first = soup.find_all('span' , {'class':'black'})\n",
    "    category = first[0].text\n",
    "    location = first[1].text\n",
    "    contract_type = first[2].text\n",
    "    exprience = first[3].text\n",
    "    salary = first[4].text\n",
    "\n",
    "    work_details = soup.find('div' , {'class':'o-box__text'}).text\n",
    "\n",
    "    processed_data={\n",
    "\n",
    "        'company' : company_name,\n",
    "        'job_title' : title,\n",
    "        'job_category' : category,\n",
    "        'job_location' : location,\n",
    "        'contract_type' : contract_type,\n",
    "        'experience' : exprience,\n",
    "        'salary' : salary,\n",
    "        'more_details' : work_details,\n",
    "        'passed_day' : passed_day,\n",
    "        'job_url' : item_url\n",
    "    }\n",
    "    print(processed_data)\n",
    "    producer.send(TOPIC_Step2_NAME, processed_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d010201",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in consumer:\n",
    "    try :\n",
    "        data=message.value\n",
    "        item_title = data['item-title']\n",
    "\n",
    "        if re.search(r'(data engineer|data engineering|مهندس داده|کاراموز|کارآموز)', item_title, re.IGNORECASE):\n",
    "            crawl_item(data['item_url'], data['passed_day'])\n",
    "\n",
    "            \n",
    "    except Exception as ex:\n",
    "        print(\"%%%-\"*20)\n",
    "        print(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
